{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 05 - Topic modeling\n",
    "\n",
    "_Goal_ :\n",
    "\n",
    "**We want to run topic modeling over the corpus to \"discover\" the main topics of the emails.**\n",
    "\n",
    "_Tools_ :\n",
    "\n",
    "**The tools used are :**\n",
    "\n",
    "* pandas\n",
    "* [gensim](https://radimrehurek.com/gensim/index.html)\n",
    "\n",
    "_Contents_ :\n",
    "\n",
    "* [1 - Loading data](#1---Loading-data)\n",
    "* [2 - Topic modeling](#2---Topic-modeling)\n",
    "* [3 - Tweaking the number of topics](#3---Tweaking-the-number-of-topics)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximepeschard/.pyenv/versions/3.5.2/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# For DataFrame pretty-printing\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place, as usual, we load the `Emails.csv` file with pandas to form a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-03T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>;H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>B6</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>Wednesday, September 12, 2012 11:52 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>05/14/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td>H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Mitchell, Andrew B</td>\n",
       "      <td>Wednesday, September 12,2012 12:44 PM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>H</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011-03-11T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "      <td>B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber                                    MetadataSubject  \\\n",
       "0   1  C05739545                                                WOW   \n",
       "1   2  C05739546  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "2   3  C05739547                                      CHRIS STEVENS   \n",
       "3   4  C05739550                         CAIRO CONDEMNATION - FINAL   \n",
       "4   5  C05739554  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "\n",
       "     MetadataTo       MetadataFrom  SenderPersonId           MetadataDateSent  \\\n",
       "0             H  Sullivan, Jacob J            87.0  2012-09-12T04:00:00+00:00   \n",
       "1             H                NaN             NaN  2011-03-03T05:00:00+00:00   \n",
       "2            ;H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "3             H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "4  Abedin, Huma                  H            80.0  2011-03-11T05:00:00+00:00   \n",
       "\n",
       "        MetadataDateReleased  \\\n",
       "0  2015-05-22T04:00:00+00:00   \n",
       "1  2015-05-22T04:00:00+00:00   \n",
       "2  2015-05-22T04:00:00+00:00   \n",
       "3  2015-05-22T04:00:00+00:00   \n",
       "4  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "1  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...       F-2015-04841   \n",
       "2  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...       F-2015-04841   \n",
       "3  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...       F-2015-04841   \n",
       "4  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "1                        ...                                 NaN   \n",
       "2                        ...                                  B6   \n",
       "3                        ...                                 NaN   \n",
       "4                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom         ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>                 NaN   \n",
       "1                                       NaN                 NaN   \n",
       "2       Mills, Cheryl D <MillsCD@state.gov>        Abedin, Huma   \n",
       "3       Mills, Cheryl D <MillsCD@state.gov>  Mitchell, Andrew B   \n",
       "4                                       NaN                 NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "1                                     NaN        F-2015-04841   \n",
       "2  Wednesday, September 12, 2012 11:52 AM        F-2015-04841   \n",
       "3   Wednesday, September 12,2012 12:44 PM        F-2015-04841   \n",
       "4                                     NaN        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "1          C05739546            05/13/2015              RELEASE IN PART   \n",
       "2          C05739547            05/14/2015              RELEASE IN PART   \n",
       "3          C05739550            05/13/2015              RELEASE IN PART   \n",
       "4          C05739554            05/13/2015              RELEASE IN PART   \n",
       "\n",
       "                                   ExtractedBodyText  \\\n",
       "0                                                NaN   \n",
       "1  B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...   \n",
       "2                                                Thx   \n",
       "3                                                NaN   \n",
       "4  H <hrod17@clintonemail.com>\\nFriday, March 11,...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "1  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "2  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "3  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "4  B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('hillary-clinton-emails/Emails.csv')\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `ExtractedBodyText` as our raw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...\n",
       "2                                                  Thx\n",
       "4    H <hrod17@clintonemail.com>\\nFriday, March 11,...\n",
       "5    Pis print.\\n-•-...-^\\nH < hrod17@clintonernail...\n",
       "7    H <hrod17@clintonemail.corn>\\nFriday, March 11...\n",
       "Name: ExtractedBodyText, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_texts = emails.ExtractedBodyText.dropna()\n",
    "raw_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data is raw, we first have to pre-process it so that our results reflect meaningful topics. To do so we simply apply the same steps as in the first assignment (tokenization, stopwords removal and stemming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "tokens = [nltk.word_tokenize(text.lower()) for text in raw_texts]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# This part is a bit empirical and domain specific\n",
    "punctuation = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', '-', '--', '...', '•', \"''\", '\"\"', '``', '@', '<', '>', \"'s\"]\n",
    "commons = ['pm','re','fw','via','fyi',\"n't\",\"'ll\",\"'m\",'ok','thx','in','the','no','yes','said','sent','mr.','call','meet','say','get','can','would','could','meeting','office']\n",
    "# We make the choice to remove any \"word\" containing digit(s) for topic modeling\n",
    "def contains_digits(s):\n",
    "    return any(c.isdigit() for c in s)\n",
    "\n",
    "stop_words.update(punctuation)\n",
    "stop_words.update(commons)\n",
    "filtered_tokens = [[t for t in tok if (t not in stop_words and len(t)>2 and not contains_digits(t))] for tok in tokens]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "texts = [[ps.stem(t) for t in tok] for tok in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hope', 'see', 'pictur', 'kamala']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous command shows that some emails are probably very short and will not necessarily help for topic modeling. That's why we decide to exclude emails that contains less than a fixed number of words.\n",
    "\n",
    "*NB : Another possiblity could be to consider **threads** (ie. emails and replies) as documents instead of single emails. We do **not** follow this approach here since it is rather time consuming to link emails together.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing short emails : 6742 emails\n",
      "After removing short emails : 3775 emails\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing short emails :\", len(texts), \"emails\")\n",
    "\n",
    "threshold = 5\n",
    "long_texts = [text for text in texts if len(text) > threshold]\n",
    "\n",
    "print(\"After removing short emails :\", len(long_texts), \"emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a dictionary containing all the words in our raw corpus. Then, we build the actual corpus that will be used to do topic modeling : it is represented as a list of lists (one per document), and each inner list contains words ids (wrt. the previously built dictionary) and corresponding number of occurences in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(long_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in long_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running LDA, let's just define a helper function to print the results in a nicer way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Helper function to print topics in a nicer way\n",
    "def print_lda_topics(lda_model, numtopics, with_probabilities=True):\n",
    "    for topic_id, topic_words in lda_model.show_topics(num_topics=numtopics, formatted=False):\n",
    "        words = list(map(lambda x: x[0], topic_words))\n",
    "        probabilities = list(map(lambda x: round(x[1],4), topic_words))\n",
    "        if with_probabilities:\n",
    "            print(\"Topic\", topic_id, ':')\n",
    "            display(pd.DataFrame([probabilities], columns=words))\n",
    "        else:\n",
    "            print(\"Topic\", topic_id, end=': ')\n",
    "            print(' | '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run LDA and print the resulting topics. We choose to focus on 5 topics for this first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secretari</th>\n",
       "      <th>state</th>\n",
       "      <th>depart</th>\n",
       "      <th>room</th>\n",
       "      <th>arriv</th>\n",
       "      <th>time</th>\n",
       "      <th>rout</th>\n",
       "      <th>privat</th>\n",
       "      <th>resid</th>\n",
       "      <th>hous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secretari   state  depart  room   arriv    time    rout  privat   resid  \\\n",
       "0     0.0218  0.0185  0.0163  0.01  0.0076  0.0075  0.0068  0.0062  0.0059   \n",
       "\n",
       "     hous  \n",
       "0  0.0055  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>state</th>\n",
       "      <th>one</th>\n",
       "      <th>want</th>\n",
       "      <th>peopl</th>\n",
       "      <th>state.gov</th>\n",
       "      <th>govern</th>\n",
       "      <th>u.s.</th>\n",
       "      <th>also</th>\n",
       "      <th>need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     work   state     one   want   peopl  state.gov  govern    u.s.    also  \\\n",
       "0  0.0058  0.0057  0.0043  0.004  0.0039     0.0038  0.0034  0.0034  0.0034   \n",
       "\n",
       "     need  \n",
       "0  0.0031  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 2 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like</th>\n",
       "      <th>presid</th>\n",
       "      <th>also</th>\n",
       "      <th>time</th>\n",
       "      <th>state</th>\n",
       "      <th>vote</th>\n",
       "      <th>govern</th>\n",
       "      <th>work</th>\n",
       "      <th>new</th>\n",
       "      <th>need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     like  presid   also    time   state    vote  govern    work     new  \\\n",
       "0  0.0044  0.0041  0.004  0.0039  0.0038  0.0037  0.0036  0.0036  0.0035   \n",
       "\n",
       "     need  \n",
       "0  0.0033  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 3 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obama</th>\n",
       "      <th>one</th>\n",
       "      <th>parti</th>\n",
       "      <th>presid</th>\n",
       "      <th>time</th>\n",
       "      <th>polit</th>\n",
       "      <th>year</th>\n",
       "      <th>republican</th>\n",
       "      <th>american</th>\n",
       "      <th>democrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obama     one   parti  presid    time  polit   year  republican  american  \\\n",
       "0  0.0053  0.0051  0.0045  0.0042  0.0042  0.004  0.004      0.0037    0.0037   \n",
       "\n",
       "   democrat  \n",
       "0    0.0035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 4 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obama</th>\n",
       "      <th>new</th>\n",
       "      <th>american</th>\n",
       "      <th>state</th>\n",
       "      <th>presid</th>\n",
       "      <th>republican</th>\n",
       "      <th>one</th>\n",
       "      <th>senat</th>\n",
       "      <th>issu</th>\n",
       "      <th>democrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obama     new  american   state  presid  republican     one   senat  \\\n",
       "0  0.0071  0.0049    0.0046  0.0044  0.0044      0.0044  0.0043  0.0037   \n",
       "\n",
       "     issu  democrat  \n",
       "0  0.0036    0.0035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "print_lda_topics(lda, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this first example, we cannot really distinguish and label topics at first sight. In the following section, we try different parameters for the number of topics and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Tweaking the number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to explore a bit the results with different number of topics for LDA. For the sake of readability, we don't print the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tnum_topics = 10\n",
      "Topic 0: state | depart | work | secretari | u.s. | new | case | hous | time | one\n",
      "Topic 1: time | one | state | polit | american | need | presid | israel | work | like\n",
      "Topic 2: secretari | state | depart | time | obama | room | presid | new | hous | privat\n",
      "Topic 3: work | women | know | state | one | help | u.s. | like | discuss | need\n",
      "Topic 4: israel | american | state | peac | govern | one | new | obama | also | isra\n",
      "Topic 5: state | senat | secretari | depart | clinton | assist | presid | work | time | nation\n",
      "Topic 6: one | obama | state | presid | boehner | work | may | parti | peopl | nation\n",
      "Topic 7: vote | like | democrat | republican | obama | one | state | presid | work | american\n",
      "Topic 8: want | also | obama | afghanistan | mcchrystal | work | see | think | one | new\n",
      "Topic 9: parti | state.gov | huma | presid | abedin | work | time | last | govern | first\n",
      "===============================================\n",
      "\t\tnum_topics = 20\n",
      "Topic 0: obama | senat | presid | republican | clinton | state | democrat | time | one | new\n",
      "Topic 1: state | gaza | palestinian | secretari | idf | direct | israel | women | depart | alexand\n",
      "Topic 2: secretari | state | presid | depart | issu | room | time | washington | obama | corpor\n",
      "Topic 3: state.gov | sullivan | cheryl | mill | jacob | millscd | presid | see | sunday | sullivanjj\n",
      "Topic 4: state | cent | empey | obama | time | secur | u.s. | like | polici | american\n",
      "Topic 5: pleas | state.gov | email | need | see | cdm | right | like | work | good\n",
      "Topic 6: one | women | american | mcchrystal | new | year | also | state | afghanistan | presid\n",
      "Topic 7: percent | poll | parti | democrat | republican | presid | tori | like | time | secretari\n",
      "Topic 8: one | work | new | state | also | year | issu | peopl | right | obama\n",
      "Topic 9: secretari | huma | may | monday | clintonemail.com | state.gov' | state.gov | abedin | print | time\n",
      "Topic 10: want | know | time | talk | also | see | make | hous | call | ask\n",
      "Topic 11: secretari | depart | state | room | arriv | rout | resid | privat | time | confer\n",
      "Topic 12: time | work | also | republican | like | voter | women | presid | parti | one\n",
      "Topic 13: obama | state | american | presid | new | peopl | u.s. | hous | polit | govern\n",
      "Topic 14: iran | vote | elect | one | want | point | voter | think | iranian | democrat\n",
      "Topic 15: one | state | time | like | day | support | presid | peopl | parti | u.s.\n",
      "Topic 16: state | time | presid | work | american | parti | obama | new | year | vote\n",
      "Topic 17: uup | parti | state | one | time | see | northern | first | like | new\n",
      "Topic 18: israel | isra | state | secretari | work | u.s. | settlement | time | support | govern\n",
      "Topic 19: state | know | women | depart | like | hous | want | secretari | case | time\n",
      "===============================================\n",
      "\t\tnum_topics = 30\n",
      "Topic 0: state | see | betsi | even | secretari | issu | may | also | china | today\n",
      "Topic 1: state | secretari | nuclear | time | talk | new | depart | know | need | today\n",
      "Topic 2: gay | new | settlement | expos | state.gov | book | state | jerusalem | israel | see\n",
      "Topic 3: secretari | depart | state | rout | room | arriv | time | resid | hous | privat\n",
      "Topic 4: state | clip | also | secretari | today | depart | pakistani | presid | new | like\n",
      "Topic 5: jewish | parti | state | senat | time | jew | one | ask | labour | need\n",
      "Topic 6: depart | secretari | state | isra | time | arriv | room | israel | resid | staff\n",
      "Topic 7: obama | state | presid | polici | polit | parti | even | foreign | american | elect\n",
      "Topic 8: israel | palestinian | obama | new | state | peac | one | peopl | say | arab\n",
      "Topic 9: uup | parti | ireland | northern | today | tomorrow | work | peac | unionist | justic\n",
      "Topic 10: women | obama | presid | one | year | govern | state | american | like | support\n",
      "Topic 11: time | obama | polici | presid | one | polit | state | american | mcchrystal | new\n",
      "Topic 12: state.gov | state | jacob | sullivan | work | speech | sullivanjj | draft | depart | bloomberg\n",
      "Topic 13: state | depart | u.s. | hous | inform | case | presid | secur | secretari | obama\n",
      "Topic 14: secretari | state | valmoro | lona | assist | special | direct | greek | op | depart\n",
      "Topic 15: marriag | princ | messag | receiv | settlement | year | e-mail | hitler | cancer | peopl\n",
      "Topic 16: israel | like | one | time | also | palestinian | huma | work | presid | sunday\n",
      "Topic 17: north | korea | strateg | reg | dialogu | one | know | press | march | truck\n",
      "Topic 18: new | year | american | state | israel | work | like | presid | public | u.s.\n",
      "Topic 19: unfavor | favor | state | vote | vol | enough | obama | refus | hrd | issu\n",
      "Topic 20: percent | secretari | poll | state | approv | like | democrat | make | republican | obama\n",
      "Topic 21: netanyahu | vote | time | isra | call | israel | also | tomorrow | today | may\n",
      "Topic 22: state.gov | cheryl | mill | millscd | huma | abedin | sullivan | see | jacob | clintonemail.com\n",
      "Topic 23: work | email | want | know | need | back | huma | talk | monday | time\n",
      "Topic 24: call | think | obama | state | draft | want | hous | incorpor | presid | good\n",
      "Topic 25: settlement | israel | state | need | time | isra | one | also | peopl | issu\n",
      "Topic 26: secretari | room | depart | privat | confer | time | washington | state | bilater | daili\n",
      "Topic 27: american | work | one | presid | boehner | govern | new | countri | like | think\n",
      "Topic 28: senat | democrat | republican | vote | obama | parti | state | polit | nation | american\n",
      "Topic 29: state | presid | beck | obama | hous | want | think | u.s. | work | bibi\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "num_topics = [10, 20, 30]\n",
    "\n",
    "for n in num_topics:\n",
    "    # Print parameter choice\n",
    "    print(\"\\t\\tnum_topics =\",n)\n",
    "    \n",
    "    # Run LDA\n",
    "    lda = LdaModel(corpus, num_topics=n, id2word=dictionary)\n",
    "    # Print results\n",
    "    print_lda_topics(lda, n, with_probabilities=False)\n",
    "    \n",
    "    # Print separator\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion on the results :**\n",
    "\n",
    "Again, due to Porter stemming, this is a sometimes a bit hard to read. Still, we can make some observations :\n",
    "* when the number of topics is small, we cannot really attribute a \"label\" to each one, they mostly share words\n",
    "* when the number increases, it becomes easier to distinguish some topics : for example with `num_topics = 30`, *Topic 8* is clearly about Israeli–Palestinian conflict, *Topic 9* is about Ireland and *Topic 20* seems to be about votes/elections.\n",
    "\n",
    "However, in most cases, a lot of topics seem irrelevant. Maybe a better pre-processing would help, since here we use a pretty basic pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
