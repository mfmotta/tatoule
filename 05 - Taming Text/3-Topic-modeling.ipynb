{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 05 - Topic modeling\n",
    "\n",
    "_Goal_ :\n",
    "\n",
    "**We want to run topic modeling over the corpus to \"discover\" the main topics of the emails.**\n",
    "\n",
    "_Tools_ :\n",
    "\n",
    "**The tools used are :**\n",
    "\n",
    "* pandas\n",
    "* [gensim](https://radimrehurek.com/gensim/index.html)\n",
    "\n",
    "_Contents_ :\n",
    "\n",
    "* [1 - Loading data](#1---Loading-data)\n",
    "* [2 - Topic modeling](#2---Topic-modeling)\n",
    "* [3 - Tweaking the number of topics](#3---Tweaking-the-number-of-topics)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximepeschard/.pyenv/versions/3.5.2/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# For DataFrame pretty-printing\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place, as usual, we load the `Emails.csv` file with pandas to form a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-03T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>;H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>B6</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>Wednesday, September 12, 2012 11:52 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>05/14/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td>H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Mitchell, Andrew B</td>\n",
       "      <td>Wednesday, September 12,2012 12:44 PM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>H</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011-03-11T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "      <td>B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber                                    MetadataSubject  \\\n",
       "0   1  C05739545                                                WOW   \n",
       "1   2  C05739546  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "2   3  C05739547                                      CHRIS STEVENS   \n",
       "3   4  C05739550                         CAIRO CONDEMNATION - FINAL   \n",
       "4   5  C05739554  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "\n",
       "     MetadataTo       MetadataFrom  SenderPersonId           MetadataDateSent  \\\n",
       "0             H  Sullivan, Jacob J            87.0  2012-09-12T04:00:00+00:00   \n",
       "1             H                NaN             NaN  2011-03-03T05:00:00+00:00   \n",
       "2            ;H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "3             H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "4  Abedin, Huma                  H            80.0  2011-03-11T05:00:00+00:00   \n",
       "\n",
       "        MetadataDateReleased  \\\n",
       "0  2015-05-22T04:00:00+00:00   \n",
       "1  2015-05-22T04:00:00+00:00   \n",
       "2  2015-05-22T04:00:00+00:00   \n",
       "3  2015-05-22T04:00:00+00:00   \n",
       "4  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "1  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...       F-2015-04841   \n",
       "2  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...       F-2015-04841   \n",
       "3  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...       F-2015-04841   \n",
       "4  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "1                        ...                                 NaN   \n",
       "2                        ...                                  B6   \n",
       "3                        ...                                 NaN   \n",
       "4                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom         ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>                 NaN   \n",
       "1                                       NaN                 NaN   \n",
       "2       Mills, Cheryl D <MillsCD@state.gov>        Abedin, Huma   \n",
       "3       Mills, Cheryl D <MillsCD@state.gov>  Mitchell, Andrew B   \n",
       "4                                       NaN                 NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "1                                     NaN        F-2015-04841   \n",
       "2  Wednesday, September 12, 2012 11:52 AM        F-2015-04841   \n",
       "3   Wednesday, September 12,2012 12:44 PM        F-2015-04841   \n",
       "4                                     NaN        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "1          C05739546            05/13/2015              RELEASE IN PART   \n",
       "2          C05739547            05/14/2015              RELEASE IN PART   \n",
       "3          C05739550            05/13/2015              RELEASE IN PART   \n",
       "4          C05739554            05/13/2015              RELEASE IN PART   \n",
       "\n",
       "                                   ExtractedBodyText  \\\n",
       "0                                                NaN   \n",
       "1  B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...   \n",
       "2                                                Thx   \n",
       "3                                                NaN   \n",
       "4  H <hrod17@clintonemail.com>\\nFriday, March 11,...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "1  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "2  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "3  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "4  B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('hillary-clinton-emails/Emails.csv')\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `ExtractedBodyText` as our raw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...\n",
       "2                                                  Thx\n",
       "4    H <hrod17@clintonemail.com>\\nFriday, March 11,...\n",
       "5    Pis print.\\n-•-...-^\\nH < hrod17@clintonernail...\n",
       "7    H <hrod17@clintonemail.corn>\\nFriday, March 11...\n",
       "Name: ExtractedBodyText, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_texts = emails.ExtractedBodyText.dropna()\n",
    "raw_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data is raw, we first have to pre-process it so that our results reflect meaningful topics. To do so we simple apply the same steps as in the first assignment (tokenization, stopwords removal and stemming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "tokens = [nltk.word_tokenize(text) for text in raw_texts]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', '-', '--', '...', '•', \"''\", '\"\"', '``', '@', '<', '>', \"'s\"]\n",
    "stop_words.update(punctuation)\n",
    "filtered_tokens = [[t for t in tok if (t not in stop_words and len(t)>1)] for tok in tokens]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [[ps.stem(t) for t in tok] for tok in filtered_tokens]\n",
    "\n",
    "texts = [[t.lower() for t in tok] for tok in stemmed_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous command shows that some emails are probably very short and do not help for topic modeling (for example if the body is just the word \"thx\"). That's why we decide to exclude emails that contains less than a fixed number of words.\n",
    "\n",
    "*NB : Another possiblity could be to consider **threads** (ie. emails and replies) as documents instead of single emails. We do **not** follow this approach here since it is rather time consuming to link emails together.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing short emails : 6742 emails\n",
      "After removing short emails : 4256 emails\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing short emails :\", len(texts), \"emails\")\n",
    "\n",
    "threshold = 5\n",
    "long_texts = [text for text in texts if len(text) > threshold]\n",
    "\n",
    "print(\"After removing short emails :\", len(long_texts), \"emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a dictionary containing all the words in our raw corpus. Then, we build the actual corpus that will be used to do topic modeling : it is represented as a list of lists (one per document), and each inner list contains words ids (wrt. the previously built dictionary) and corresponding number of occurences in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(long_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in long_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running LDA, let's just define a helper function to print the results in a nicer way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Helper function to print topics in a nicer way\n",
    "def print_lda_topics(lda_model, numtopics, with_probabilities=True):\n",
    "    for topic_id, topic_words in lda_model.show_topics(num_topics=numtopics, formatted=False):\n",
    "        words = list(map(lambda x: x[0], topic_words))\n",
    "        probabilities = list(map(lambda x: round(x[1],4), topic_words))\n",
    "        if with_probabilities:\n",
    "            print(\"Topic\", topic_id)\n",
    "            display(pd.DataFrame([probabilities], columns=words))\n",
    "        else:\n",
    "            print(\"Topic\", topic_id, end=' : ')\n",
    "            print(' | '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run LDA and print the resulting topics. We choose to focus on 5 topics for this first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>call</th>\n",
       "      <th>said</th>\n",
       "      <th>senat</th>\n",
       "      <th>would</th>\n",
       "      <th>2010</th>\n",
       "      <th>obama</th>\n",
       "      <th>bill</th>\n",
       "      <th>n't</th>\n",
       "      <th>get</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      the    call    said   senat   would    2010   obama   bill     n't  \\\n",
       "0  0.0067  0.0055  0.0042  0.0041  0.0037  0.0033  0.0032  0.003  0.0029   \n",
       "\n",
       "      get  \n",
       "0  0.0028  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2010</th>\n",
       "      <th>pm</th>\n",
       "      <th>b6</th>\n",
       "      <th>state.gov</th>\n",
       "      <th>call</th>\n",
       "      <th>am</th>\n",
       "      <th>see</th>\n",
       "      <th>know</th>\n",
       "      <th>1.4</th>\n",
       "      <th>re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2010      pm      b6  state.gov    call      am     see    know     1.4  \\\n",
       "0  0.0104  0.0069  0.0067     0.0064  0.0062  0.0058  0.0049  0.0048  0.0048   \n",
       "\n",
       "       re  \n",
       "0  0.0047  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>would</th>\n",
       "      <th>state</th>\n",
       "      <th>american</th>\n",
       "      <th>n't</th>\n",
       "      <th>new</th>\n",
       "      <th>presid</th>\n",
       "      <th>obama</th>\n",
       "      <th>make</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      the  would   state  american     n't     new  presid   obama    make  \\\n",
       "0  0.0094  0.007  0.0053    0.0047  0.0046  0.0041   0.004  0.0037  0.0035   \n",
       "\n",
       "      one  \n",
       "0  0.0035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm</th>\n",
       "      <th>secretari</th>\n",
       "      <th>offic</th>\n",
       "      <th>depart</th>\n",
       "      <th>state</th>\n",
       "      <th>the</th>\n",
       "      <th>meet</th>\n",
       "      <th>room</th>\n",
       "      <th>time</th>\n",
       "      <th>treati</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm  secretari   offic  depart   state     the    meet    room    time  \\\n",
       "0  0.0278     0.0172  0.0145  0.0131  0.0106  0.0096  0.0092  0.0085  0.0064   \n",
       "\n",
       "   treati  \n",
       "0  0.0061  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>state</th>\n",
       "      <th>new</th>\n",
       "      <th>u.s.</th>\n",
       "      <th>forc</th>\n",
       "      <th>but</th>\n",
       "      <th>obama</th>\n",
       "      <th>in</th>\n",
       "      <th>war</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      the   state     new    u.s.   forc     but   obama      in     war  \\\n",
       "0  0.0092  0.0079  0.0057  0.0049  0.004  0.0036  0.0035  0.0034  0.0034   \n",
       "\n",
       "    would  \n",
       "0  0.0034  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "\n",
    "print_lda_topics(lda, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this first example, we cannot really distinguish topics at first sight. In the following section, we try different parameters for the number of topics and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Tweaking the number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to explore a bit the results with different number of topics for LDA. For the sake of simplicity, we don't print the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tnum_topics = 10\n",
      "Topic 0 : the | in | would | parti | time | n't | david | us | call | american\n",
      "Topic 1 : the | state | would | n't | american | make | said | new | one | but\n",
      "Topic 2 : vote | senat | the | new | republican | obama | democrat | presid | one | parti\n",
      "Topic 3 : 2010 | state.gov | b6 | pm | fw | see | part | want | in | am\n",
      "Topic 4 : the | state | u.s. | nation | make | peopl | unit | new | start | support\n",
      "Topic 5 : pm | secretari | offic | depart | room | meet | state | arriv | rout | confer\n",
      "Topic 6 : mod | state | pm | depart | the | expeditionari | bibi | time | we | meet\n",
      "Topic 7 : the | state | new | would | presid | obama | work | time | year | diplomat\n",
      "Topic 8 : call | n't | know | 2010 | am | go | get | re | 'm | monday\n",
      "Topic 9 : state | the | pm | depart | 2010 | secretari | no | presid | n't | offic\n",
      "===============================================\n",
      "\t\tnum_topics = 20\n",
      "Topic 0 : melann | notetak | pm | houston | min | verveerm | b6 | verif | verveer | pl\n",
      "Topic 1 : call | talk | want | tomorrow | today | would | work | know | need | see\n",
      "Topic 2 : the | state | forc | diplomat | iraq | support | would | presid | offici | cabl\n",
      "Topic 3 : pm | secretari | depart | state | clinton | offic | time | meet | the | bloomberg\n",
      "Topic 4 : chapter | the | jockey | get | forgot | work | see | 1.4 | want | catherin\n",
      "Topic 5 : we | know | he | make | said | get | birthday | boehner | one | want\n",
      "Topic 6 : 2010 | 1.4 | re | septemb | am | marriag | pm | sunday | sender | 26\n",
      "Topic 7 : the | american | state | make | obama | peopl | n't | time | support | in\n",
      "Topic 8 : 1.4 | state | u.s. | b1 | would | the | work | new | unit | leak\n",
      "Topic 9 : the | librari | email | would | time | jill | offic | thi | pm | here\n",
      "Topic 10 : 10 | amb | van | palin | 24 | email | the | add | want | pa\n",
      "Topic 11 : state | the | israel | conflict | bloomberg | negoti | bibi | secur | isra | govern\n",
      "Topic 12 : releas | state | b6 | in | part | the | secretari | ,1.4 | b1,1.4 | assist\n",
      "Topic 13 : 2010 | clintonemail.com | hrod17 | state.gov | am | re | state.gov' | pm | monday | fw\n",
      "Topic 14 : b6 | state | no | depart | waldorf-astoria | to | b5 | meet | in | releas\n",
      "Topic 15 : the | would | one | women | n't | new | year | afghanistan | senat | said\n",
      "Topic 16 : pm | secretari | offic | depart | room | meet | state | arriv | confer | rout\n",
      "Topic 17 : n't | get | the | 'm | work | good | know | see | day | also\n",
      "Topic 18 : the | senat | vote | call | mod | go | would | start | one | let\n",
      "Topic 19 : the | new | obama | would | presid | nuclear | said | parti | republican | democrat\n",
      "===============================================\n",
      "\t\tnum_topics = 30\n",
      "Topic 0 : bibi | palestinian | negoti | we | state | n't | work | jewish | time | day\n",
      "Topic 1 : pm | secretari | offic | depart | room | meet | state | arriv | treati | rout\n",
      "Topic 2 : 2010 | pm | state.gov | call | clintonemail.com | am | re | hrod17 | b6 | fw\n",
      "Topic 3 : mr. | richard | like | work | the | 'm | 'd | he | call | anytim\n",
      "Topic 4 : would | state | the | diplomaci | need | diplomat | presid | new | u.s. | american\n",
      "Topic 5 : fco | the | state | would | french | book | diplomat | wikileak | fox | n't\n",
      "Topic 6 : the | fgm | rwanda | also | da | carlo | would | a/gi | state | classifi\n",
      "Topic 7 : 1.4 | ,1.4 | b1,1.4 | in | verif | releas | b1 | part | pm | would\n",
      "Topic 8 : b6 | pm | sullivan | 2010 | pa | sunday | ani | via | amb | sent\n",
      "Topic 9 : the | nuclear | obama | presid | american | state | u.s. | new | republican | polit\n",
      "Topic 10 : israel | the | would | like | one | said | isra | time | netanyahu | say\n",
      "Topic 11 : boehner | jockey | said | the | cargo | intellectu | hous | next | work | gay\n",
      "Topic 12 : camera | aipac | email | isabel | still | pleas | have | nice | wheel | nuke\n",
      "Topic 13 : n't | 2010 | anywher | enough | favor | catherin | 48 | presid | unfavor | obama\n",
      "Topic 14 : state | the | diplomaci | develop | depart | u.s. | secretari | unit | work | intern\n",
      "Topic 15 : the | new | obama | state | would | american | one | presid | support | in\n",
      "Topic 16 : labour | parti | the | would | miliband | david | member | mp | elect | cameron\n",
      "Topic 17 : senat | vote | would | said | the | new | state | clotur | reid | start\n",
      "Topic 18 : diplomat | u.s. | state | the | would | need | make | unit | n't | govern\n",
      "Topic 19 : palin | the | 2010 | iran | pm | time | kennedi | librari | state | nation\n",
      "Topic 20 : count | netanyahu | settlement | log | arturo | 2010 | the | fuch | valenzuelaaa | altho\n",
      "Topic 21 : state | blackberri | call | no | sent | you | colombia | talk | u.s. | to\n",
      "Topic 22 : mod | moscow | 'jilotylc | b6 | releas | part | in | thank | pi | 4th\n",
      "Topic 23 : notetak | waldorf-astoria | forgot | state | pm | lona | secretari | depart | lucki | valmoro\n",
      "Topic 24 : 1.4 | chapter | b1 | want | declassifi | reason | see | e. | think | draft\n",
      "Topic 25 : email | he | b5 | b6 | van | limit | flight | blair | visa | govt\n",
      "Topic 26 : bloomberg | the | pool | state | new | simultan | ashton | secur | said | nation\n",
      "Topic 27 : kennedi | mr. | state | would | said | the | verveer | he | ambassador | verveerm\n",
      "Topic 28 : mazen | bibi | pm | the | abu | secretari | state | offic | meet | depart\n",
      "Topic 29 : the | qddr | n't | new | would | go | tea | said | state | he\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "num_topics = [10, 20, 30]\n",
    "\n",
    "for n in num_topics:\n",
    "    # Print parameter choice\n",
    "    print(\"\\t\\tnum_topics =\",n)\n",
    "    \n",
    "    # Run LDA\n",
    "    lda = LdaModel(corpus, num_topics=n, id2word=dictionary)\n",
    "    # Print results\n",
    "    print_lda_topics(lda, n, with_probabilities=False)\n",
    "    \n",
    "    # Print separator\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion on the results :**\n",
    "\n",
    "Again, due to short \"words\" not excluded and to Porter stemming, this is a bit hard to read. Still, we can distinguish some topics like *Topic 11* for `num_topics = 20` which is clearly about Israeli–Palestinian conflict or *Topic 2* for the same parameter which seems to be about diplomacy.\n",
    "\n",
    "However, in most cases, a lot of topics seem irrelevant. Maybe a better pre-processing would help, since there are a lot or short \"meaningless\" words left, as well as common \"communication vocabulary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
